{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All districts\n",
    "import pandas as pd\n",
    "\n",
    "def Reverse(lst): \n",
    "    return [ele for ele in reversed(lst)] \n",
    "\n",
    "df=pd.read_csv('patients.csv')\n",
    "district_df = df.groupby('detecteddistrict')\n",
    "district_list=[]\n",
    "total_cases_list=[]\n",
    "for name, group in district_df:  \n",
    "    district_list.append(name)\n",
    "    total_cases_list.append(len(group.index))\n",
    "\n",
    "consolidated_df=pd.DataFrame(list(zip(district_list, total_cases_list)), \n",
    "               columns =['district_name', 'total_cases']) \n",
    "consolidated_df.sort_values(by=['total_cases'], inplace=True, ascending=False)\n",
    "consolidated_df.to_csv('district_final.csv', header=False, index=False)\n",
    "\n",
    "for district in district_list:\n",
    "  mum_df=district_df.get_group(district)\n",
    "  mum_df_1=mum_df[['currentstatus','dateannounced','detecteddistrict','statuschangedate']]\n",
    "\n",
    "  confirmed_list=[]\n",
    "  deceased_list=[]\n",
    "  recovered_list=[]\n",
    "\n",
    "  confirmed_total=[]\n",
    "  deceased_total=[]\n",
    "  recovered_total=[]\n",
    "\n",
    "  confirmed_t=0\n",
    "  deceased_t=0\n",
    "  recovered_t=0\n",
    "\n",
    "  date_list=mum_df_1.dateannounced.unique()\n",
    "  date_list=Reverse(date_list)\n",
    "\n",
    "  for date in date_list:\n",
    "    confirmed=0\n",
    "    deceased=0\n",
    "    recovered=0\n",
    "    for index, row in mum_df_1.iterrows(): \n",
    "      if(row['dateannounced']==date):\n",
    "        confirmed+=1\n",
    "      if(row['statuschangedate']==date and row['currentstatus']=='Recovered'):\n",
    "        recovered+=1\n",
    "      if(row['statuschangedate']==date and row['currentstatus']=='Deceased'):\n",
    "        deceased+=1 \n",
    "  \n",
    "    confirmed_t+=confirmed\n",
    "    deceased_t+=deceased\n",
    "    recovered_t+=recovered\n",
    "  \n",
    "    confirmed_list.append(confirmed)\n",
    "    confirmed_total.append(confirmed_t)\n",
    "    deceased_list.append(deceased)\n",
    "    deceased_total.append(deceased_t)\n",
    "    recovered_list.append(recovered) \n",
    "    recovered_total.append(recovered_t)\n",
    "\n",
    "  final_df=pd.DataFrame(list(zip(date_list, confirmed_list, confirmed_total, recovered_list, recovered_total, deceased_list, deceased_total)), \n",
    "               columns =['date', 'confirmed_cases', 'total_confirmed', 'recovered_cases', 'total_recovered', 'deceased_cases', 'total_deceased'])\n",
    "  if(district=='Italians*'):\n",
    "    final_df.to_csv('Italians'+'.csv', header=False, index=False)\n",
    "    continue\n",
    "  if(district=='Other Region*'):\n",
    "    final_df.to_csv('Other_Region'+'.csv', header=False, index=False)\n",
    "    continue\n",
    "  if(district=='Other States*'):\n",
    "    final_df.to_csv('Other_States'+'.csv', header=False, index=False)\n",
    "    continue\n",
    "  if(district=='Gujarat*'):\n",
    "    final_df.to_csv('Gujarat'+'.csv', header=False, index=False)\n",
    "    continue\n",
    "  final_df.to_csv(district+'.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('patients.csv')\n",
    "district_df = df.groupby('detecteddistrict')\n",
    "\n",
    "district_list=[]\n",
    "total_deaths_list=[]\n",
    "total_cases_list=[]\n",
    "mortality_rate_list=[]\n",
    "\n",
    "for name, group in district_df:  \n",
    "    d=0\n",
    "    district_list.append(name)\n",
    "    confirmed_cases=len(group.index)\n",
    "    total_cases_list.append(confirmed_cases)\n",
    "    for index, row in group.iterrows():\n",
    "        if(row['currentstatus']=='Deceased'):\n",
    "            d=d+1\n",
    "    total_deaths_list.append(d)\n",
    "    mortality=(d/confirmed_cases)*100\n",
    "    mortality_rate_list.append(mortality)\n",
    "\n",
    "consolidated_df=pd.DataFrame(list(zip(district_list, total_cases_list, total_deaths_list, mortality_rate_list)), \n",
    "               columns =['district_name', 'total_cases', 'total_deaths', 'mortality_rates']) \n",
    "consolidated_df.sort_values(by=['total_deaths'], inplace=True, ascending=False)\n",
    "consolidated_df.to_csv('district_mortality_sort.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agebracket                                                                           NaN\n",
      "backupnotes                                Travelled to Singapore (Feb) and Canada (Mar)\n",
      "contractedfromwhichpatientsuspected                                                  NaN\n",
      "currentstatus                                                                   Migrated\n",
      "dateannounced                                                                 17/03/2020\n",
      "detectedcity                                                                       Saket\n",
      "detecteddistrict                                                             South Delhi\n",
      "detectedstate                                                                      Delhi\n",
      "estimatedonsetdate                                                                   NaN\n",
      "gender                                                                               NaN\n",
      "nationality                                                                        India\n",
      "notes                                    Travelled from Singapore (Feb) and Canada (Mar)\n",
      "patientnumber                                                                        130\n",
      "source1                                http://health.delhigovt.nic.in/wps/wcm/connect...\n",
      "source2                                https://www.hindustantimes.com/delhi-news/delh...\n",
      "source3                                                                              NaN\n",
      "statecode                                                                             DL\n",
      "statepatientnumber                                                                 DL-P8\n",
      "statuschangedate                                                              20/03/2020\n",
      "typeoftransmission                                                              Imported\n",
      "Name: 7377, dtype: object\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "m=0\n",
    "df=pd.read_csv('patients.csv')\n",
    "df['currentstatus'].unique()\n",
    "for index, row in df.iterrows():\n",
    "    if(row['currentstatus']=='Migrated'):\n",
    "        print(row)\n",
    "    if(row['currentstatus']=='Deceased'):\n",
    "        m=m+1\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('patients.csv')\n",
    "state_df = df.groupby('detectedstate')\n",
    "\n",
    "state_list=[]\n",
    "total_deaths_list=[]\n",
    "total_cases_list=[]\n",
    "mortality_rate_list=[]\n",
    "\n",
    "for name, group in state_df:  \n",
    "    d=0\n",
    "    state_list.append(name)\n",
    "    confirmed_cases=len(group.index)\n",
    "    total_cases_list.append(confirmed_cases)\n",
    "    for index, row in group.iterrows():\n",
    "        if(row['currentstatus']=='Deceased'):\n",
    "            d=d+1\n",
    "    total_deaths_list.append(d)\n",
    "    mortality=(d/confirmed_cases)*100\n",
    "    mortality_rate_list.append(mortality)\n",
    "\n",
    "consolidated_df=pd.DataFrame(list(zip(state_list, total_cases_list, total_deaths_list, mortality_rate_list)), \n",
    "               columns =['state_name', 'total_cases', 'total_deaths', 'mortality_rates']) \n",
    "consolidated_df.sort_values(by=['total_deaths'], inplace=True, ascending=False)\n",
    "consolidated_df.to_csv('state_mortality_sort.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('patients.csv')\n",
    "all_state_df=df.groupby('detectedstate')\n",
    "\n",
    "maha_df=all_state_df.get_group('Maharashtra')\n",
    "\n",
    "district_df = maha_df.groupby('detecteddistrict')\n",
    "\n",
    "district_list=[]\n",
    "total_deaths_list=[]\n",
    "total_cases_list=[]\n",
    "mortality_rate_list=[]\n",
    "\n",
    "for name, group in district_df:  \n",
    "    d=0\n",
    "    district_list.append(name)\n",
    "    confirmed_cases=len(group.index)\n",
    "    total_cases_list.append(confirmed_cases)\n",
    "    for index, row in group.iterrows():\n",
    "        if(row['currentstatus']=='Deceased'):\n",
    "            d=d+1\n",
    "    total_deaths_list.append(d)\n",
    "    mortality=(d/confirmed_cases)*100\n",
    "    mortality_rate_list.append(mortality)\n",
    "\n",
    "consolidated_df=pd.DataFrame(list(zip(district_list, total_cases_list, total_deaths_list, mortality_rate_list)), \n",
    "               columns =['district_name', 'total_cases', 'total_deaths', 'mortality_rates']) \n",
    "consolidated_df.sort_values(by=['total_deaths'], inplace=True, ascending=False)\n",
    "consolidated_df.to_csv('Maharashtra_mortality_sort.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All districts\n",
    "import pandas as pd\n",
    "\n",
    "def Reverse(lst): \n",
    "    return [ele for ele in reversed(lst)] \n",
    "\n",
    "df=pd.read_csv('patients.csv')\n",
    "district_df = df.groupby('detecteddistrict')\n",
    "district_list=[]\n",
    "total_cases_list=[]\n",
    "for name, group in district_df:  \n",
    "    district_list.append(name)\n",
    "    total_cases_list.append(len(group.index))\n",
    "\n",
    "consolidated_df=pd.DataFrame(list(zip(district_list, total_cases_list)), \n",
    "               columns =['district_name', 'total_cases']) \n",
    "consolidated_df.sort_values(by=['total_cases'], inplace=True, ascending=False)\n",
    "#consolidated_df.to_csv('district_final.csv', header=False, index=False)\n",
    "\n",
    "edit_list=['Mumbai','Thane','Indore','Kurnool','Jaipur','Pune','Chennai','Bengaluru','Ahmadabad','Bhopal']\n",
    "\n",
    "for district in edit_list:\n",
    "  mum_df=district_df.get_group(district)\n",
    "  mum_df_1=mum_df[['currentstatus','dateannounced','detecteddistrict','statuschangedate']]\n",
    "\n",
    "  confirmed_list=[]\n",
    "  deceased_list=[]\n",
    "  recovered_list=[]\n",
    "\n",
    "  confirmed_total=[]\n",
    "  deceased_total=[]\n",
    "  recovered_total=[]\n",
    "\n",
    "  confirmed_t=0\n",
    "  deceased_t=0\n",
    "  recovered_t=0\n",
    "\n",
    "  date_list=mum_df_1.dateannounced.unique()\n",
    "  date_list=Reverse(date_list)\n",
    "\n",
    "  for date in date_list:\n",
    "    confirmed=0\n",
    "    deceased=0\n",
    "    recovered=0\n",
    "    for index, row in mum_df_1.iterrows(): \n",
    "      if(row['dateannounced']==date):\n",
    "        confirmed+=1\n",
    "      if(row['statuschangedate']==date and row['currentstatus']=='Recovered'):\n",
    "        recovered+=1\n",
    "      if(row['statuschangedate']==date and row['currentstatus']=='Deceased'):\n",
    "        deceased+=1 \n",
    "  \n",
    "    confirmed_t+=confirmed\n",
    "    deceased_t+=deceased\n",
    "    recovered_t+=recovered\n",
    "  \n",
    "    confirmed_list.append(confirmed)\n",
    "    confirmed_total.append(confirmed_t)\n",
    "    deceased_list.append(deceased)\n",
    "    deceased_total.append(deceased_t)\n",
    "    recovered_list.append(recovered) \n",
    "    recovered_total.append(recovered_t)\n",
    "  \n",
    "  final_df=pd.DataFrame(list(zip(date_list, confirmed_list, confirmed_total, recovered_list, recovered_total, deceased_list, deceased_total)), \n",
    "               columns =['A','B','C','D','E','F','G'])\n",
    "  final_df.to_csv(\"csv_files/{}\".format(district+'.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             A   B    C  D  E  F  G\n",
      "0   02/03/2020   0    0  0  0  0  0\n",
      "1   03/03/2020   0    0  0  0  0  0\n",
      "2   04/03/2020   0    0  0  0  0  0\n",
      "3   05/03/2020   0    0  0  0  0  0\n",
      "4   06/03/2020   0    0  0  0  0  0\n",
      "5   07/03/2020   0    0  0  0  0  0\n",
      "6   08/03/2020   0    0  0  0  0  0\n",
      "7   09/03/2020   0    0  0  0  0  0\n",
      "8   10/03/2020   0    0  0  0  0  0\n",
      "9   11/03/2020   0    0  0  0  0  0\n",
      "10  12/03/2020   0    0  0  0  0  0\n",
      "11  13/03/2020   0    0  0  0  0  0\n",
      "12  14/03/2020   0    0  0  0  0  0\n",
      "13  15/03/2020   0    0  0  0  0  0\n",
      "14  16/03/2020   0    0  0  0  0  0\n",
      "15  17/03/2020   0    0  0  0  0  0\n",
      "16  18/03/2020   0    0  0  0  0  0\n",
      "17  19/03/2020   0    0  0  0  0  0\n",
      "18  20/03/2020   3    3  1  1  0  0\n",
      "19  21/03/2020   2    5  0  1  0  0\n",
      "20  22/03/2020   3    8  0  1  0  0\n",
      "21  23/03/2020   6   14  0  1  0  0\n",
      "22  28/03/2020   3   17  0  1  0  0\n",
      "23  29/03/2020   4   21  0  1  0  0\n",
      "24  30/03/2020   1   22  0  1  0  0\n",
      "25  31/03/2020   1   23  0  1  0  0\n",
      "26  01/04/2020   8   31  0  1  0  0\n",
      "27  03/04/2020   7   38  0  1  0  0\n",
      "28  04/04/2020   7   45  0  1  0  0\n",
      "29  05/04/2020   8   53  0  1  0  0\n",
      "30  06/04/2020  11   64  0  1  0  0\n",
      "31  07/04/2020  19   83  0  1  0  0\n",
      "32  09/04/2020  59  142  0  1  0  0\n",
      "33  10/04/2020  55  197  0  1  0  0\n",
      "             A  B   C  D   E  F  G\n",
      "0   02/03/2020  0   0  0   0  0  0\n",
      "1   03/03/2020  0   0  0   0  0  0\n",
      "2   04/03/2020  0   0  0   0  0  0\n",
      "3   05/03/2020  0   0  0   0  0  0\n",
      "4   06/03/2020  0   0  0   0  0  0\n",
      "5   07/03/2020  0   0  0   0  0  0\n",
      "6   08/03/2020  0   0  0   0  0  0\n",
      "7   09/03/2020  1   1  0   0  0  0\n",
      "8   10/03/2020  3   4  0   0  0  0\n",
      "9   12/03/2020  1   5  0   0  0  0\n",
      "10  16/03/2020  1   6  1   1  0  0\n",
      "11  17/03/2020  2   8  1   2  0  0\n",
      "12  18/03/2020  3  11  3   5  0  0\n",
      "13  21/03/2020  3  14  0   5  0  0\n",
      "14  22/03/2020  3  17  1   6  0  0\n",
      "15  23/03/2020  6  23  2   8  0  0\n",
      "16  24/03/2020  1  24  2  10  0  0\n",
      "17  25/03/2020  8  32  0  10  0  0\n",
      "18  26/03/2020  2  34  0  10  0  0\n",
      "19  27/03/2020  4  38  2  12  0  0\n",
      "20  28/03/2020  2  40  0  12  0  0\n",
      "21  31/03/2020  4  44  0  12  0  0\n",
      "22  01/04/2020  3  47  1  13  0  0\n",
      "23  04/04/2020  4  51  0  13  0  0\n",
      "24  05/04/2020  2  53  0  13  0  0\n",
      "25  06/04/2020  2  55  0  13  0  0\n",
      "26  07/04/2020  3  58  0  13  0  0\n",
      "27  08/04/2020  1  59  0  13  0  0\n",
      "28  09/04/2020  5  64  0  13  0  0\n",
      "29  10/04/2020  2  66  0  13  0  0\n",
      "             A   B    C  D  E  F  G\n",
      "0   02/03/2020   0    0  0  0  0  0\n",
      "1   03/03/2020   0    0  0  0  0  0\n",
      "2   04/03/2020   0    0  0  0  0  0\n",
      "3   05/03/2020   0    0  0  0  0  0\n",
      "4   06/03/2020   0    0  0  0  0  0\n",
      "5   07/03/2020   0    0  0  0  0  0\n",
      "6   08/03/2020   0    0  0  0  0  0\n",
      "7   09/03/2020   0    0  0  0  0  0\n",
      "8   10/03/2020   0    0  0  0  0  0\n",
      "9   11/03/2020   0    0  0  0  0  0\n",
      "10  12/03/2020   0    0  0  0  0  0\n",
      "11  13/03/2020   0    0  0  0  0  0\n",
      "12  14/03/2020   0    0  0  0  0  0\n",
      "13  15/03/2020   0    0  0  0  0  0\n",
      "14  16/03/2020   0    0  0  0  0  0\n",
      "15  17/03/2020   0    0  0  0  0  0\n",
      "16  18/03/2020   0    0  0  0  0  0\n",
      "17  19/03/2020   0    0  0  0  0  0\n",
      "18  20/03/2020   0    0  0  0  0  0\n",
      "19  21/03/2020   0    0  0  0  0  0\n",
      "20  22/03/2020   1    1  0  0  0  0\n",
      "21  25/03/2020   1    2  0  0  0  0\n",
      "22  27/03/2020   1    3  0  0  0  0\n",
      "23  02/04/2020   5    8  0  0  0  0\n",
      "24  04/04/2020   7   15  0  0  0  0\n",
      "25  05/04/2020   3   18  0  0  0  0\n",
      "26  06/04/2020  43   61  0  0  0  0\n",
      "27  07/04/2020  24   85  0  0  0  0\n",
      "28  08/04/2020   9   94  0  0  0  0\n",
      "29  09/04/2020   4   98  0  0  0  0\n",
      "30  10/04/2020  18  116  0  0  0  0\n",
      "             A   B    C  D  E  F  G\n",
      "0   02/03/2020   0    0  0  0  0  0\n",
      "1   03/03/2020   0    0  0  0  0  0\n",
      "2   04/03/2020   0    0  0  0  0  0\n",
      "3   05/03/2020   0    0  0  0  0  0\n",
      "4   06/03/2020   0    0  0  0  0  0\n",
      "5   07/03/2020   0    0  0  0  0  0\n",
      "6   08/03/2020   0    0  0  0  0  0\n",
      "7   09/03/2020   0    0  0  0  0  0\n",
      "8   10/03/2020   0    0  0  0  0  0\n",
      "9   11/03/2020   0    0  0  0  0  0\n",
      "10  12/03/2020   0    0  0  0  0  0\n",
      "11  13/03/2020   0    0  0  0  0  0\n",
      "12  14/03/2020   0    0  0  0  0  0\n",
      "13  15/03/2020   0    0  0  0  0  0\n",
      "14  16/03/2020   0    0  0  0  0  0\n",
      "15  17/03/2020   0    0  0  0  0  0\n",
      "16  18/03/2020   1    1  0  0  0  0\n",
      "17  19/03/2020   1    2  0  0  0  0\n",
      "18  21/03/2020   1    3  0  0  0  0\n",
      "19  22/03/2020   1    4  0  0  0  0\n",
      "20  23/03/2020   1    5  0  0  0  0\n",
      "21  24/03/2020   6   11  0  0  0  0\n",
      "22  25/03/2020   1   12  0  0  0  0\n",
      "23  26/03/2020   2   14  0  0  0  0\n",
      "24  27/03/2020   3   17  0  0  0  0\n",
      "25  28/03/2020   1   18  1  1  0  0\n",
      "26  30/03/2020   5   23  0  1  0  0\n",
      "27  31/03/2020   5   28  0  1  0  0\n",
      "28  01/04/2020   1   29  0  1  0  0\n",
      "29  02/04/2020  20   49  0  1  0  0\n",
      "30  03/04/2020  35   84  0  1  0  0\n",
      "31  04/04/2020   7   91  0  1  0  0\n",
      "32  05/04/2020   7   98  0  1  0  0\n",
      "33  06/04/2020  15  113  0  1  0  0\n",
      "34  07/04/2020  39  152  0  1  0  0\n",
      "35  08/04/2020   7  159  0  1  0  0\n",
      "36  09/04/2020   7  166  0  1  0  0\n",
      "37  10/04/2020   9  175  0  1  0  0\n",
      "             A   B    C  D  E  F  G\n",
      "0   02/03/2020   0    0  0  0  0  0\n",
      "1   03/03/2020   0    0  0  0  0  0\n",
      "2   04/03/2020   0    0  0  0  0  0\n",
      "3   05/03/2020   0    0  0  0  0  0\n",
      "4   06/03/2020   0    0  0  0  0  0\n",
      "5   07/03/2020   0    0  0  0  0  0\n",
      "6   08/03/2020   0    0  0  0  0  0\n",
      "7   09/03/2020   0    0  0  0  0  0\n",
      "8   10/03/2020   0    0  0  0  0  0\n",
      "9   11/03/2020   0    0  0  0  0  0\n",
      "10  12/03/2020   0    0  0  0  0  0\n",
      "11  13/03/2020   0    0  0  0  0  0\n",
      "12  14/03/2020   0    0  0  0  0  0\n",
      "13  15/03/2020   0    0  0  0  0  0\n",
      "14  16/03/2020   0    0  0  0  0  0\n",
      "15  17/03/2020   0    0  0  0  0  0\n",
      "16  18/03/2020   0    0  0  0  0  0\n",
      "17  19/03/2020   0    0  0  0  0  0\n",
      "18  20/03/2020   0    0  0  0  0  0\n",
      "19  21/03/2020   0    0  0  0  0  0\n",
      "20  22/03/2020   0    0  0  0  0  0\n",
      "21  23/03/2020   0    0  0  0  0  0\n",
      "22  24/03/2020   0    0  0  0  0  0\n",
      "23  25/03/2020   4    4  0  0  0  0\n",
      "24  26/03/2020   5    9  0  0  0  0\n",
      "25  27/03/2020   5   14  0  0  1  1\n",
      "26  28/03/2020   6   20  0  0  0  1\n",
      "27  30/03/2020   7   27  0  0  0  1\n",
      "28  31/03/2020  18   45  0  0  0  1\n",
      "29  01/04/2020  32   77  0  0  0  1\n",
      "30  02/04/2020   2   79  0  0  0  1\n",
      "31  03/04/2020  35  114  0  0  0  1\n",
      "32  04/04/2020  14  128  0  0  0  1\n",
      "33  05/04/2020   7  135  0  0  0  1\n",
      "34  06/04/2020  16  151  0  0  0  1\n",
      "35  08/04/2020  22  173  0  0  0  1\n",
      "36  09/04/2020  48  221  0  0  0  1\n",
      "37  10/04/2020  14  235  0  0  0  1\n",
      "             A   B    C  D  E  F  G\n",
      "0   02/03/2020   0    0  0  0  0  0\n",
      "1   03/03/2020   0    0  0  0  0  0\n",
      "2   04/03/2020   0    0  0  0  0  0\n",
      "3   05/03/2020   0    0  0  0  0  0\n",
      "4   06/03/2020   0    0  0  0  0  0\n",
      "5   07/03/2020   0    0  0  0  0  0\n",
      "6   08/03/2020   0    0  0  0  0  0\n",
      "7   09/03/2020   0    0  0  0  0  0\n",
      "8   10/03/2020   1    1  1  1  0  0\n",
      "9   14/03/2020   1    2  0  1  0  0\n",
      "10  19/03/2020   2    4  0  1  0  0\n",
      "11  20/03/2020   2    6  0  1  0  0\n",
      "12  26/03/2020   1    7  0  1  0  0\n",
      "13  27/03/2020   1    8  0  1  0  0\n",
      "14  30/03/2020  10   18  0  1  0  0\n",
      "15  31/03/2020   1   19  0  1  0  0\n",
      "16  01/04/2020  13   32  0  1  0  0\n",
      "17  02/04/2020   7   39  0  1  0  0\n",
      "18  03/04/2020  14   53  0  1  0  0\n",
      "19  05/04/2020  39   92  0  1  0  0\n",
      "20  06/04/2020   8  100  0  1  0  0\n",
      "21  07/04/2020   6  106  0  1  0  0\n",
      "22  08/04/2020  23  129  0  1  0  0\n",
      "23  09/04/2020  39  168  0  1  0  0\n",
      "24  10/04/2020  15  183  0  1  0  0\n",
      "             A   B   C  D  E  F  G\n",
      "0   02/03/2020   0   0  0  0  0  0\n",
      "1   03/03/2020   0   0  0  0  0  0\n",
      "2   04/03/2020   0   0  0  0  0  0\n",
      "3   05/03/2020   0   0  0  0  0  0\n",
      "4   06/03/2020   0   0  0  0  0  0\n",
      "5   07/03/2020   0   0  0  0  0  0\n",
      "6   08/03/2020   0   0  0  0  0  0\n",
      "7   09/03/2020   0   0  0  0  0  0\n",
      "8   10/03/2020   0   0  0  0  0  0\n",
      "9   11/03/2020   0   0  0  0  0  0\n",
      "10  12/03/2020   0   0  0  0  0  0\n",
      "11  13/03/2020   0   0  0  0  0  0\n",
      "12  14/03/2020   0   0  0  0  0  0\n",
      "13  15/03/2020   0   0  0  0  0  0\n",
      "14  16/03/2020   0   0  0  0  0  0\n",
      "15  17/03/2020   0   0  0  0  0  0\n",
      "16  18/03/2020   0   0  0  0  0  0\n",
      "17  19/03/2020   0   0  0  0  0  0\n",
      "18  20/03/2020   0   0  0  0  0  0\n",
      "19  21/03/2020   0   0  0  0  0  0\n",
      "20  22/03/2020   0   0  0  0  0  0\n",
      "21  23/03/2020   0   0  0  0  0  0\n",
      "22  24/03/2020   0   0  0  0  0  0\n",
      "23  25/03/2020   0   0  0  0  0  0\n",
      "24  26/03/2020   0   0  0  0  0  0\n",
      "25  27/03/2020   0   0  0  0  0  0\n",
      "26  28/03/2020   1   1  0  0  0  0\n",
      "27  04/04/2020   3   4  0  0  0  0\n",
      "28  05/04/2020  49  53  0  0  0  0\n",
      "29  06/04/2020  21  74  0  0  0  0\n",
      "30  07/04/2020   1  75  0  0  0  0\n",
      "31  10/04/2020   2  77  0  0  0  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             A    B    C  D  E  F  G\n",
      "0   02/03/2020    0    0  0  0  0  0\n",
      "1   03/03/2020    0    0  0  0  0  0\n",
      "2   04/03/2020    0    0  0  0  0  0\n",
      "3   05/03/2020    0    0  0  0  0  0\n",
      "4   06/03/2020    0    0  0  0  0  0\n",
      "5   07/03/2020    0    0  0  0  0  0\n",
      "6   08/03/2020    0    0  0  0  0  0\n",
      "7   09/03/2020    0    0  0  0  0  0\n",
      "8   10/03/2020    0    0  0  0  0  0\n",
      "9   11/03/2020    2    2  0  0  0  0\n",
      "10  12/03/2020    1    3  0  0  1  1\n",
      "11  14/03/2020    4    7  0  0  0  1\n",
      "12  16/03/2020    3   10  0  0  0  1\n",
      "13  17/03/2020    1   11  0  0  0  1\n",
      "14  18/03/2020    1   12  0  0  0  1\n",
      "15  19/03/2020    1   13  0  0  0  1\n",
      "16  20/03/2020    4   17  0  0  0  1\n",
      "17  21/03/2020    7   24  0  0  0  1\n",
      "18  22/03/2020    5   29  0  0  1  2\n",
      "19  23/03/2020   12   41  0  0  0  2\n",
      "20  24/03/2020    2   43  0  0  0  2\n",
      "21  25/03/2020    8   51  0  0  0  2\n",
      "22  26/03/2020    1   52  0  0  0  2\n",
      "23  27/03/2020    3   55  0  0  0  2\n",
      "24  28/03/2020   25   80  0  0  0  2\n",
      "25  29/03/2020    5   85  0  0  0  2\n",
      "26  30/03/2020    7   92  0  0  0  2\n",
      "27  31/03/2020   59  151  0  0  0  2\n",
      "28  01/04/2020   30  181  0  0  0  2\n",
      "29  02/04/2020   54  235  0  0  0  2\n",
      "30  03/04/2020   43  278  0  0  0  2\n",
      "31  04/04/2020   99  377  0  0  0  2\n",
      "32  05/04/2020   81  458  0  0  0  2\n",
      "33  06/04/2020   68  526  0  0  0  2\n",
      "34  07/04/2020  116  642  0  0  0  2\n",
      "35  08/04/2020   72  714  0  0  0  2\n",
      "36  09/04/2020  162  876  0  0  0  2\n",
      "             A   B    C  D  E  F  G\n",
      "0   02/03/2020   0    0  0  0  0  0\n",
      "1   03/03/2020   0    0  0  0  0  0\n",
      "2   04/03/2020   0    0  0  0  0  0\n",
      "3   05/03/2020   0    0  0  0  0  0\n",
      "4   06/03/2020   0    0  0  0  0  0\n",
      "5   07/03/2020   0    0  0  0  0  0\n",
      "6   08/03/2020   0    0  0  0  0  0\n",
      "7   09/03/2020   2    2  0  0  0  0\n",
      "8   10/03/2020   3    5  0  0  0  0\n",
      "9   11/03/2020   3    8  0  0  0  0\n",
      "10  12/03/2020   1    9  0  0  0  0\n",
      "11  13/03/2020   1   10  0  0  0  0\n",
      "12  14/03/2020   5   15  0  0  0  0\n",
      "13  16/03/2020   1   16  0  0  0  0\n",
      "14  17/03/2020   1   17  0  0  0  0\n",
      "15  18/03/2020   2   19  0  0  0  0\n",
      "16  20/03/2020   2   21  0  0  0  0\n",
      "17  21/03/2020   2   23  0  0  0  0\n",
      "18  22/03/2020   4   27  0  0  0  0\n",
      "19  23/03/2020   1   28  0  0  0  0\n",
      "20  24/03/2020   3   31  0  0  0  0\n",
      "21  27/03/2020   1   32  0  0  0  0\n",
      "22  29/03/2020   5   37  0  0  0  0\n",
      "23  30/03/2020   6   43  0  0  0  0\n",
      "24  31/03/2020   5   48  0  0  0  0\n",
      "25  01/04/2020   2   50  0  0  0  0\n",
      "26  02/04/2020  11   61  0  0  0  0\n",
      "27  03/04/2020   9   70  0  0  0  0\n",
      "28  04/04/2020  12   82  0  0  0  0\n",
      "29  05/04/2020  18  100  0  0  0  0\n",
      "30  06/04/2020  41  141  0  0  0  0\n",
      "31  07/04/2020  18  159  0  0  0  0\n",
      "32  08/04/2020  38  197  0  0  0  0\n",
      "33  09/04/2020   9  206  0  0  0  0\n",
      "             A   B    C  D  E  F  G\n",
      "0   02/03/2020   0    0  0  0  0  0\n",
      "1   03/03/2020   0    0  0  0  0  0\n",
      "2   04/03/2020   0    0  0  0  0  0\n",
      "3   05/03/2020   0    0  0  0  0  0\n",
      "4   06/03/2020   0    0  0  0  0  0\n",
      "5   07/03/2020   0    0  0  0  0  0\n",
      "6   08/03/2020   0    0  0  0  0  0\n",
      "7   09/03/2020   0    0  0  0  0  0\n",
      "8   10/03/2020   0    0  0  0  0  0\n",
      "9   11/03/2020   0    0  0  0  0  0\n",
      "10  12/03/2020   1    1  0  0  0  0\n",
      "11  14/03/2020   1    2  0  0  0  0\n",
      "12  16/03/2020   2    4  0  0  0  0\n",
      "13  19/03/2020   1    5  0  0  0  0\n",
      "14  22/03/2020   1    6  0  0  0  0\n",
      "15  23/03/2020   2    8  0  0  0  0\n",
      "16  24/03/2020   6   14  0  0  0  0\n",
      "17  25/03/2020   2   16  0  0  0  0\n",
      "18  27/03/2020   2   18  0  0  0  0\n",
      "19  28/03/2020   1   19  0  0  0  0\n",
      "20  29/03/2020   4   23  0  0  0  0\n",
      "21  31/03/2020  13   36  0  0  0  0\n",
      "22  02/04/2020   9   45  0  0  0  0\n",
      "23  03/04/2020  10   55  0  0  0  0\n",
      "24  04/04/2020  22   77  0  0  0  0\n",
      "25  05/04/2020   5   82  0  0  0  0\n",
      "26  06/04/2020   3   85  0  0  0  0\n",
      "27  07/04/2020   2   87  0  0  0  0\n",
      "28  08/04/2020   5   92  0  0  0  0\n",
      "29  09/04/2020  22  114  0  0  0  0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "entries = os.listdir('csv_files/')\n",
    "\n",
    "def Insert_row_(row_number, df, row_value): \n",
    "    # Slice the upper half of the dataframe \n",
    "    df1 = df[0:row_number] \n",
    "   \n",
    "    # Store the result of lower half of the dataframe \n",
    "    df2 = df[row_number:] \n",
    "   \n",
    "    # Inser the row in the upper half dataframe \n",
    "    df1.loc[row_number]=row_value \n",
    "   \n",
    "    # Concat the two dataframes \n",
    "    df_result = pd.concat([df1, df2]) \n",
    "   \n",
    "    # Reassign the index labels \n",
    "    df_result.index = [*range(df_result.shape[0])] \n",
    "   \n",
    "    # Return the updated dataframe \n",
    "    return df_result \n",
    "\n",
    "for y in entries:\n",
    "    df = pd.read_csv(\"csv_files/{}\".format(y))\n",
    "    first_date = df.at[0, 'A']\n",
    "    first_date = int(first_date.split('/')[0])\n",
    "\n",
    "    i = 2\n",
    "\n",
    "    for x in range(i,first_date):\n",
    "        if (x < 10):\n",
    "            df = Insert_row_(x-i, df, [\"0{}/03/2020\".format(x), 0, 0, 0, 0, 0, 0])\n",
    "        else:\n",
    "            df = Insert_row_(x-i, df, [\"{}/03/2020\".format(x), 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "    print (df)\n",
    "\n",
    "    df.to_csv(\"csv_files_normalized/{}\".format(y), header=False, index=False)\n",
    "\n",
    "    df_rows = df.shape[0]\n",
    "    last_date = df.at[df_rows-1, 'A']\n",
    "    last_date_int = int(last_date.split('/')[0])\n",
    "\n",
    "    j = 1\n",
    "\n",
    "    date = first_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import csv\n",
    "\n",
    "N, T, t_l, t_e, t_changeKt, kspread = None, None, None, None, None, None # Set later depending on country\n",
    "samplesPerDay = 10\n",
    "\n",
    "startingTested = 14\n",
    "daysOffset = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THE SIER-X MODEL\n",
    "def getPreds(beta = 0.2, beta1 = 0.1, sigma = 1/38.0, plot = False):\n",
    "    global N, T, t_l, t_e, t_changeKt, kspread\n",
    "    # Total population, N.\n",
    "\n",
    "    # Initial number of infected and recovered individuals, I0 and R0.\n",
    "    # Everyone else, S0, is susceptible to infection initially.\n",
    "\n",
    "    K0 = 1./7\n",
    "    MU = 1./7\n",
    "    gamma1 = 1./19\n",
    "    gamma2 = 1./14\n",
    "    gamma3 = 1./14\n",
    "    b1 = beta1\n",
    "    b2 = 0.1 * beta1\n",
    "    b3 = 0.002 * beta1\n",
    "    \n",
    "#     A0, I0, Xs0, Xa0, Xi0, P0, R0 = 1, 0, 0, 0, 0, 0, 0\n",
    "    totalInfected = startingTested * 20; pIgivenA = 0.33\n",
    "    A0 = totalInfected * (1.0 - pIgivenA) ;P0 = startingTested;I0 = totalInfected * pIgivenA - P0 ;Xs0 = 0;Xa0 = 0;Xi0 = 0; R0 = 0\n",
    "    \n",
    "    S0 = N - A0 - I0 - Xs0 - Xa0 - Xi0 - P0 - R0\n",
    "\n",
    "    t = np.linspace(0, T, samplesPerDay*T)\n",
    "\n",
    "    def deriv(y, t, N, beta):\n",
    "        S, A, I, Xs, Xa, Xi, P, R = y\n",
    "\n",
    "        if t < t_l or t > t_e:\n",
    "            k0 = 0\n",
    "        else:\n",
    "            k0 = K0\n",
    "            \n",
    "        if t > t_changeKt:\n",
    "            kt = kt2 = 0.5\n",
    "        else:\n",
    "            kt = 0.075; kt2 = 0\n",
    "\n",
    "        if t > t_e:\n",
    "            mu = MU\n",
    "        else:\n",
    "            mu = 0\n",
    "\n",
    "        dSdt = - beta * (I + kspread * (A + b1 * Xa) + b2 * Xi + b3 * P) * S/N - k0 * S + mu * Xs\n",
    "        dAdt = beta * (I + kspread * (A + b1 * Xa) + b2 * Xi + b3 * P) * S/N - sigma * A - k0 * A + mu * Xa - gamma1 * A - kt2 * A\n",
    "        dIdt = sigma * A  - kt * I - k0 * I + mu * Xi - gamma2 * I\n",
    "\n",
    "        dXsdt = - beta * beta1 * (I + kspread * (A + b1 * Xa) + b2 * Xi + b3 * P) * Xs/N + k0 * S - mu * Xs\n",
    "        dXadt = beta * beta1 * (I + kspread * (A + b1 * Xa) + b2 * Xi + b3 * P) * Xs/N - sigma * Xa + k0 * A - mu * Xa - gamma1 * Xa - kt2 * Xa\n",
    "        dXidt = sigma * Xa - kt * Xi + k0 * I - mu * Xi - gamma2 * Xi\n",
    "\n",
    "        dPdt = kt * (I + Xi) - gamma3 * P + kt2 * (A + Xa)\n",
    "        dRdt = gamma1 * (A + Xa) + gamma2 * (I + Xi) + gamma3 * P\n",
    "\n",
    "        return dSdt, dAdt, dIdt, dXsdt, dXadt, dXidt, dPdt, dRdt\n",
    "\n",
    "    # Initial conditions vector\n",
    "    y0 = S0, A0, I0, Xs0, Xa0, Xi0, P0, R0\n",
    "    # Integrate the SIR equations over the time grid, t.\n",
    "    ret = odeint(deriv, y0, t, args=(N, beta))\n",
    "    S, A, I, Xs, Xa, Xi, P, R = ret.T\n",
    "    if not plot: return P, R\n",
    "    else: return P, I + Xi + P, P + I + Xi + A + Xa\n",
    "\n",
    "# temp = getPreds(0.31, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDataMaharashtra(startIndex = 0):\n",
    "    file = open('Mumbai.csv', 'r')\n",
    "    reader = csv.reader(file)\n",
    "    confirmed, recovered, dead = None, None, None\n",
    "    count = -1\n",
    "    i, r = [], []\n",
    "    for row in reader:\n",
    "        count += 1\n",
    "        if count < startIndex: continue\n",
    "        confirmed = int(row[2])\n",
    "        recovered = int(row[4])\n",
    "        dead = int(row[6])\n",
    "        r.append(recovered + dead)\n",
    "        i.append(confirmed - r[-1])\n",
    "    file.close()\n",
    "    return i, r\n",
    "\n",
    "# Start from March 01, when the first case in this spread started, adjust counts as needed\n",
    "# actualI, actualR = readDataIndia(startDate = \"01 March\")\n",
    "# T = 50\n",
    "# t_l = 23 # From 24 March, ignore Janta Curfew?\n",
    "# t_e = 44\n",
    "# actualI = np.asarray(actualI); actualR = np.asarray(actualR)\n",
    "# N = 1300000000\n",
    "\n",
    "# actualI, actualR = readDataIndia(startDate = \"01 March\")\n",
    "# T = 50 - daysOffset\n",
    "# t_l = 23 - daysOffset# From 24 March, ignore Janta Curfew?\n",
    "# t_e = 44 - daysOffset\n",
    "# actualI = np.asarray(actualI[daysOffset:]); actualR = np.asarray(actualR[daysOffset:])\n",
    "# N = 1300000000\n",
    "\n",
    "\n",
    "# Maharashtra Data\n",
    "actualI, actualR = readDataMaharashtra()\n",
    "actualI = np.asarray(actualI); actualR = np.asarray(actualR)\n",
    "T = 62 - daysOffset\n",
    "t_l = 24 - daysOffset\n",
    "t_e = 24 + 21 - daysOffset\n",
    "N = 110000000\n",
    "t_changeKt = 1000000000\n",
    "kspread = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and search for the best hyperparameters (grid search for now)\n",
    "def squaredLoss(preds, target):\n",
    "    loss = ((preds - target) ** 2).sum()\n",
    "    return loss\n",
    "\n",
    "eps = 1e-8\n",
    "def squaredLossExpScale(preds, target):\n",
    "    preds = np.log(preds + eps)\n",
    "    target = np.log(target + eps)\n",
    "    loss = ((preds - target) ** 2).sum()\n",
    "    return loss\n",
    "\n",
    "bestLoss = 10000000000\n",
    "bestBeta, bestBeta1 = -1, -1\n",
    "bestPreds = None\n",
    "betaValues = np.linspace(0.1, 0.6, 51)\n",
    "beta1Values = np.linspace(0.6, 1.0, 41)\n",
    "losses = np.zeros((len(betaValues), len(beta1Values)))\n",
    "\n",
    "for i, beta in enumerate(betaValues):\n",
    "    for j, beta1 in enumerate(beta1Values):\n",
    "        predI, predR = getPreds(beta = beta, beta1 = beta1)\n",
    "        trimmedPredI = predI[:len(actualI) * samplesPerDay:samplesPerDay]\n",
    "        trimmedPredR = predR[:len(actualR) * samplesPerDay:samplesPerDay]\n",
    "        assert len(trimmedPredI) == len(actualI) and len(trimmedPredR) == len(actualR), \"Length mismatch\"\n",
    "        loss = squaredLoss(trimmedPredI, actualI)\n",
    "        losses[i, j] = loss\n",
    "        \n",
    "        if loss < bestLoss:\n",
    "            bestLoss = loss\n",
    "            bestPreds = predI, predR\n",
    "            bestBeta = beta; bestBeta1 = beta1\n",
    "\n",
    "print(\"Best beta value\", bestBeta)\n",
    "print(\"Best beta1 value\", bestBeta1)\n",
    "print(\"Best loss value\", bestLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
